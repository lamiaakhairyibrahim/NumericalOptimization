# Numerical Optimization
 - [Overview](#overview)
 - [Topics](#topics)


 ## Overview
  - For this practical work, we will have to develop a Python program that is able to implement the type of gradient descent variants in order to achieve the linear regression of a set of datasets.

## Topics
 - ### 1. Gradient descent
     - ### *Step1*:
      Initialize parameters (theta_0 & theta_1) with random value or simply zero ,Also choose the Learning rate.

     - ### *Step2*:
      Use (theta_0 & theta_1) to predict the output h(x)= theta_0 + theta_1 * x.

     - ### *Step3*:
      Calculate Cost function ùë±(theta_0,theta_1 ).

     - ### *Step4*:
      Calculate the gradient.

     - ### *Step5*:
      Update the parameters (simultaneously).

     - ### *Step6*:
      Repeat from 2 to 5 until converge to the minimum or achieve maximum iterations.
